{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparison_of_performance_of_age&gender_predicting_models_in_voice_b&a_combining_stat_method.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hakseong1231/DACD-AudioSignalAnalysis/blob/main/Comparison_of_performance_of_age%26gender_predicting_models_in_voice_b%26a_combining_stat_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HeMKgiSZMa6"
      },
      "source": [
        "# Modeling with mean MFCC for each .wav files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMQBZAUrfUlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78952ed5-b775-4ce8-fb98-69c5c4956a0f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53MW0hX2tcjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce70ab70-d2b0-4b18-93e6-a2fdca706636"
      },
      "source": [
        "!pip install praat-parselmouth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: praat-parselmouth in /usr/local/lib/python3.6/dist-packages (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from praat-parselmouth) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeZe6BPw5unM"
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import scipy.io.wavfile as wavf\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import parselmouth  # Extract f0, jitter, shimmer, NHR from .wav file\n",
        "from parselmouth.praat import call\n",
        "from scipy.stats import norm  # Calculate value of probability density function of normal distribution\n",
        "from sklearn import linear_model  # Logistic Regression module\n",
        "from sklearn.ensemble import RandomForestClassifier  # Random Forest module\n",
        "from sklearn.svm import SVC  # SVM module\n",
        "from math import ceil\n",
        "from sklearn.externals import joblib  # Use to save models\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import warnings  # Remove warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "sr = 16000  # Signal Rate\n",
        "categories = ['20F', '20M', '30M', '40F', '50F', '50M']\n",
        "wav_unprocessed = \"/content/drive/My Drive/DACD/DACD_unprocessed/\"  # num of files [18590, 16433, 17661, 18589, 7698, 8077]\n",
        "wav_processed = \"/content/drive/My Drive/DACD/DACD_processed/\"\n",
        "wav_pickle = \"/content/drive/MyDrive/DACD/DACD_pickle/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOsHSKaSsKSF"
      },
      "source": [
        "# Part 1. Generate Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqWiD4sTDKho"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJx_c4jH6Cut"
      },
      "source": [
        "def remove_silence(wav_dir):\n",
        "  \"\"\"Remove data in .wav file if it's too small\"\"\"\n",
        "\n",
        "  # y: Sound Pressure, sr: Number of datas per 1 second\n",
        "  y, _ = librosa.load(wav_dir, sr=sr)\n",
        "\n",
        "  # cut: Reference that determines whether to remove data\n",
        "  cut = max(y) / 300\n",
        "  y = pd.DataFrame(y)\n",
        "  y = y[abs(y[0]) > cut].to_numpy()\n",
        "  return y.T[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-reFKNtL6Ued",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5225ea47-1de2-4c6f-a359-18274e0f1fdd"
      },
      "source": [
        "\"\"\"Run remove_silence() for every .wav file in wav_unprocessed directory and save results\"\"\"\n",
        "\n",
        "run = input(\"Run? [Y/N] \")\n",
        "if run in ['Y', 'y']:\n",
        "  X_mfcc = pd.DataFrame([])\n",
        "  y_label = pd.DataFrame([], columns=[\"y_label\"])\n",
        "  for category in os.listdir(wav_unprocessed):\n",
        "    if category not in categories:\n",
        "      continue\n",
        "\n",
        "    print(\"[Now Processing]\", category)\n",
        "\n",
        "    save_dir = wav_processed + \"processed_\" + category + \"/\"\n",
        "    if not os.path.isdir(save_dir):\n",
        "      os.mkdir(save_dir)\n",
        "\n",
        "    for folder in os.listdir(wav_unprocessed + category):\n",
        "      folder_dir = wav_unprocessed + category + \"/\"\n",
        "\n",
        "      for file in os.listdir(folder_dir + folder):\n",
        "        if file.endswith(\".wav\"):\n",
        "          wav = folder_dir + folder + \"/\" + file  # Path of unprocessed sound files\n",
        "          save = save_dir + category + \"_\" + file[5:]  # Save path\n",
        "          try:\n",
        "            # Save means of MFCC vectors of processed sound files\n",
        "            y = remove_silence(wav)\n",
        "            X_mfcc = pd.concat([X_mfcc, pd.DataFrame(pd.DataFrame(librosa.feature.mfcc(y=y, sr=sr)).mean(axis=1)[1:]).T], axis=0, ignore_index=True)  # [1:]: Remove data on [0] with poor information\n",
        "            y_label = pd.concat([y_label, pd.DataFrame([category[-3:]], columns=[\"y_label\"])], axis=0, ignore_index=True)\n",
        "          except:\n",
        "            continue\n",
        "\n",
        "  print(\"[Finished]\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run? [Y/N] Y\n",
            "[Now Processing] 20F\n",
            "[Now Processing] 20M\n",
            "[Now Processing] 30M\n",
            "[Now Processing] 50F\n",
            "[Now Processing] 40F\n",
            "[Now Processing] 50M\n",
            "[Finished]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRy3IQejvFjn"
      },
      "source": [
        "\"\"\"Save mean value of MFCC vectors of .wav files\"\"\"\n",
        "\n",
        "result.to_pickle(wav_pickle + \"X_mfcc.pkl\")\n",
        "y_label.to_pickle(wav_pickle + \"y_label.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PucRkt9qzqZD"
      },
      "source": [
        "Load MFCC vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgGkt4P-wL8H"
      },
      "source": [
        "X_mfcc = pd.read_pickle(wav_pickle + \"X_mfcc.pkl\")\n",
        "y_label = pd.read_pickle(wav_pickle + \"y_label.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJc5HTSHgCFB"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_mfcc, y_label, test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bJF1iMUuq4I"
      },
      "source": [
        "Generate & Save Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfjg4Tw13xEL"
      },
      "source": [
        "\"\"\"1. Logistic Regression\"\"\"\n",
        "\n",
        "logreg = linear_model.LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Save models\n",
        "if not os.path.isfile(wav_pickle + \"model_LogisticRegression.pkl\"):\n",
        "  joblib.dump(logreg, wav_pickle + \"model_LogisticRegression.pkl\")\n",
        "\n",
        "# Save prediction results\n",
        "y_pred = pd.DataFrame(logreg.predict(X_test), columns=[\"y_label\"])\n",
        "if not os.path.isfile(wav_pickle + \"y_pred_LR.pkl\"):\n",
        "  y_pred.to_pickle(wav_pickle + \"y_pred_LR.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLTb-Suuau4k"
      },
      "source": [
        "\"\"\"2. Random Forest\"\"\"\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=50, max_depth=15)\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "# Save models\n",
        "if not os.path.isfile(wav_pickle + \"model_RandomForest.pkl\"):\n",
        "  joblib.dump(forest, wav_pickle + \"model_RandomForest.pkl\")\n",
        "\n",
        "# Save prediction results\n",
        "y_pred = pd.DataFrame(forest.predict(X_test), columns=[\"y_label\"])\n",
        "if not os.path.isfile(wav_pickle + \"y_pred_RF.pkl\"):\n",
        "  y_pred.to_pickle(wav_pickle + \"y_pred_RF.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzvTdTHkorji"
      },
      "source": [
        "\"\"\"3. Support Vector Machine\"\"\"\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Save models\n",
        "if not os.path.isfile(wav_pickle + \"model_SVM.pkl\"):\n",
        "  joblib.dump(svm, wav_pickle + \"model_SVM.pkl\")\n",
        "\n",
        "# Save prediction results\n",
        "y_pred = pd.DataFrame(svm.predict(X_test), columns=[\"y_label\"])\n",
        "if not os.path.isfile(wav_pickle + \"y_pred_SVM.pkl\"):\n",
        "  y_pred.to_pickle(wav_pickle + \"y_pred_SVM.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lar7bokEtFtm"
      },
      "source": [
        "Validate Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF3x_ETgtLCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e11390e-6712-427e-aac8-bc9e274135f4"
      },
      "source": [
        "\"\"\"1. Logistic Regression\"\"\"\n",
        "\n",
        "y_pred = pd.read_pickle(wav_pickle + \"y_pred_LR.pkl\")\n",
        "\n",
        "# Validate model performance\n",
        "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5002   55   14  406  124   28]\n",
            " [  78 3970  630   27   18  247]\n",
            " [  10  577 4180    4   11  417]\n",
            " [ 478   61   31 4456  447   73]\n",
            " [ 306   18   79 1087  758   70]\n",
            " [  53  417  455  121   46 1360]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.8439    0.8886    0.8657      5629\n",
            "         20M     0.7787    0.7988    0.7886      4970\n",
            "         30M     0.7757    0.8040    0.7896      5199\n",
            "         40F     0.7304    0.8035    0.7652      5546\n",
            "         50F     0.5399    0.3270    0.4073      2318\n",
            "         50M     0.6196    0.5546    0.5853      2452\n",
            "\n",
            "    accuracy                         0.7554     26114\n",
            "   macro avg     0.7147    0.6961    0.7003     26114\n",
            "weighted avg     0.7458    0.7554    0.7475     26114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKGkhVEhtNCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbae7bd-7749-403f-fab1-459d6a2f6b3b"
      },
      "source": [
        "\"\"\"2. Random Forest\"\"\"\n",
        "\n",
        "y_pred = pd.read_pickle(wav_pickle + \"y_pred_RF.pkl\")\n",
        "\n",
        "# Validate model performance\n",
        "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5497   34    8   77   10    3]\n",
            " [  11 4866   58    5    2   28]\n",
            " [   1   67 5104    2    1   24]\n",
            " [ 136   17    9 5356   23    5]\n",
            " [ 118   19    3  229 1944    5]\n",
            " [  16   58   70    8   11 2289]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.9512    0.9766    0.9637      5629\n",
            "         20M     0.9615    0.9791    0.9702      4970\n",
            "         30M     0.9718    0.9817    0.9767      5199\n",
            "         40F     0.9435    0.9657    0.9545      5546\n",
            "         50F     0.9764    0.8387    0.9023      2318\n",
            "         50M     0.9724    0.9335    0.9526      2452\n",
            "\n",
            "    accuracy                         0.9595     26114\n",
            "   macro avg     0.9628    0.9459    0.9533     26114\n",
            "weighted avg     0.9598    0.9595    0.9591     26114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqr6mYb6t5zl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5ad3f1-e6c9-4454-bd86-16bab25bba38"
      },
      "source": [
        "\"\"\"3. Support Vector Machine\"\"\"\n",
        "\n",
        "y_pred = pd.read_pickle(wav_pickle + \"y_pred_SVM.pkl\")\n",
        "\n",
        "# Validate model performance\n",
        "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5327   14    3  215   64    6]\n",
            " [  18 4711  155    2    6   78]\n",
            " [   1  183 4935    4    2   74]\n",
            " [ 326   33    9 5094   77    7]\n",
            " [ 294   18    4  728 1256   18]\n",
            " [  34  127  243   42   27 1979]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.8878    0.9463    0.9162      5629\n",
            "         20M     0.9263    0.9479    0.9370      4970\n",
            "         30M     0.9226    0.9492    0.9357      5199\n",
            "         40F     0.8371    0.9185    0.8759      5546\n",
            "         50F     0.8771    0.5418    0.6699      2318\n",
            "         50M     0.9154    0.8071    0.8578      2452\n",
            "\n",
            "    accuracy                         0.8923     26114\n",
            "   macro avg     0.8944    0.8518    0.8654     26114\n",
            "weighted avg     0.8929    0.8923    0.8881     26114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPMS-kxnsUC1"
      },
      "source": [
        "# Part 2. Generate Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXM3zD1wwVHi"
      },
      "source": [
        "Load Sample File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5222bPPaQxuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f19bec6-84a7-4f6c-ff49-5f8d91228f21"
      },
      "source": [
        "sample_dir = wav_unprocessed + \"20F/fv01/fv01_t01_s01.wav\"\n",
        "sample = remove_silence(sample_dir)\n",
        "print(sample.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32665,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp5YOVMng56w"
      },
      "source": [
        "Mean Value and Standard Error extracted from wav file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohUt9zElaeRD"
      },
      "source": [
        "\"\"\"mean f0, jitter, shimmer, NHR by age and gender group\"\"\"\n",
        "\n",
        "# m = E(X): Mean value\n",
        "# s = s.e.(X): standard error\n",
        "# y = P(X) = 1/(s*(2*np.pi)**.5) * np.exp(-(X-m)**2/(2*s**2)): Value of probability density function\n",
        "\n",
        "cat_num = len(categories)  # = 6, categories = ['20F', '20M', '30M', '40F', '50F', '50M']\n",
        "attrs = [\"f0\", \"jitter\", \"shimmer\", \"NHR\"]\n",
        "attr_num = len(attrs)  # = 4\n",
        "\n",
        "\n",
        "# 20F, 20M, 30M, 40F, 50F, 50M\n",
        "\n",
        "m_f0 = [206.26, 111.75, 116.53, 198.81, 199.38, 126.24]\n",
        "s_f0 = [20.04, 15.47, 19.34, 25.47, 30.15, 25.73]\n",
        "\n",
        "m_jitter = [0.14, 0.23, 0.22, 0.14, 0.15, 0.27]\n",
        "s_jitter = [0.12, 0.11, 0.10, 0.12, 0.12, 0.22]\n",
        "\n",
        "m_shimmer = [5.67, 5.72, 6.12, 5.53, 7.20, 7.82]\n",
        "s_shimmer = [4.20, 4.41, 5.10, 4.30, 5.87, 7.21]\n",
        "\n",
        "m_nhr = [0.014, 0.017, 0.018, 0.011, 0.017, 0.032]\n",
        "s_nhr = [0.02, 0.02, 0.02, 0.02, 0.03, 0.06]\n",
        "\n",
        "\n",
        "# f0, jitter, shimmer, NHR\n",
        "\n",
        "m_20f = [206.26, 0.14, 5.67, 0.014]\n",
        "s_20f = [20.04, 0.12, 4.20, 0.02]\n",
        "\n",
        "m_20m = [111.75, 0.23, 5.72, 0.017]\n",
        "s_20m = [15.47, 0.11, 4.41, 0.02]\n",
        "\n",
        "m_30m = [116.53, 0.22, 6.12, 0.018]\n",
        "s_30m = [19.34, 0.10, 5.10, 0.02]\n",
        "\n",
        "m_40f = [198.81, 0.14, 5.53, 0.011]\n",
        "s_40f = [25.47, 0.12, 4.30, 0.02]\n",
        "\n",
        "m_50f = [199.38, 0.15, 7.20, 0.017]\n",
        "s_50f = [30.15, 0.12, 5.87, 0.03]\n",
        "\n",
        "m_50m = [126.24, 0.27, 7.82, 0.032]\n",
        "s_50m = [25.73, 0.22, 7.21, 0.06]\n",
        "\n",
        "m_list = [m_20f, m_20m, m_30m, m_40f, m_50f, m_50m]\n",
        "s_list = [s_20f, s_20m, s_30m, s_40f, s_50f, s_50m]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5De7eN2D5gP"
      },
      "source": [
        "Find f0, Jitter, Shimmer, NHR with ParselMouth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqRAGmFKEEiw"
      },
      "source": [
        "def get_features(wav_dir):\n",
        "  \"\"\"Returns mean f0, nhr, localJitter, localShimmer\"\"\"\n",
        "\n",
        "  # 75Hz: min F0, 500Hz: max F0\n",
        "  sound = parselmouth.Sound(wav_dir)\n",
        "  pitch = call(sound, \"To Pitch\", 0.0, 75, 500)  # Create praat pitch object\n",
        "  meanF0 = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
        "  harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
        "  hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
        "  nhr = 1/(10**(hnr / 10) + 1)  # HNR->NHR transmutation\n",
        "  pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
        "  localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "  localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "  \n",
        "  return meanF0, localJitter, localShimmer, nhr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTCCMQfzH9cj"
      },
      "source": [
        "Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHs6LNkcmtto"
      },
      "source": [
        "def statistical_probability(x, m, s):\n",
        "  \"\"\"Calculates the probability that an object belongs to each category\"\"\"\n",
        "\n",
        "  #  Calculate the probability density function value for category i of object x for each attribute\n",
        "  y = []\n",
        "  for i in range(cat_num):\n",
        "    y.append(list())\n",
        "    for j in range(attr_num):\n",
        "      y[i].append(norm.pdf(x[j], m[i][j], s[i][j]))\n",
        "  df = pd.DataFrame(y, index=categories, columns=attrs)\n",
        "\n",
        "  # Normalize to make the sum of each column be 1\n",
        "  for col in df.columns:\n",
        "    df[col] = df[col] / df[col].sum(axis=0)\n",
        "\n",
        "  # Calculate the sum for each column\n",
        "  df = df.sum(axis=1)\n",
        "\n",
        "  # Normalize to make the sum of each sum be 1\n",
        "  df = df/df.sum(axis=0)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14i-ktAzxJcH"
      },
      "source": [
        "logreg = joblib.load(wav_pickle + \"model_LogisticRegression.pkl\")\n",
        "rand = joblib.load(wav_pickle + \"model_RandomForest.pkl\")\n",
        "svm = joblib.load(wav_pickle + \"model_SVM.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX0k2WkPegOS",
        "outputId": "ee232045-f74c-463d-919e-925c9db21e92"
      },
      "source": [
        "def logreg_probability(wav_dir):\n",
        "  \"\"\"Returns the probability that an object belongs to each category using Logistic Regression\"\"\"\n",
        "  \n",
        "  # # 1. Classify using mean value of whole MFCC vectors of a wav file\n",
        "  # y = remove_silence(wav_dir)\n",
        "  # mfcc = pd.DataFrame(librosa.feature.mfcc(y=y, sr=sr))[1:].T\n",
        "  # result = pd.DataFrame(logreg.predict(mfcc)).value_counts()/len(mfcc)  # Result of classification of Logistic Regression\n",
        "\n",
        "  # # Modify index from ('20F', ) to '20F'\n",
        "  # result.index = [idx[0] for idx in result.index]\n",
        "\n",
        "\n",
        "  # # 2. Divide a wav file in 'Division' and get probability of each category (prob = counts / Division)\n",
        "  # division = 7\n",
        "  # y = remove_silence(wav_dir)\n",
        "  # result = []\n",
        "  # for i in range(0, len(y), ceil(len(y)/division)):\n",
        "  #   mfcc = pd.DataFrame(pd.DataFrame(librosa.feature.mfcc(y=y[i:i + ceil(len(y)/division)], sr=sr)).mean(axis=1)[1:]).T\n",
        "  #   result.append(logreg.predict(mfcc))\n",
        "\n",
        "  # result = pd.DataFrame(result).value_counts() / division\n",
        "  # result.index = [idx[0] for idx in result.index]\n",
        "\n",
        "  \n",
        "  # 3. Extract MFCC vectors randomly from wav file at a constant rate\n",
        "  y = remove_silence(wav_dir)\n",
        "  mfcc = pd.DataFrame(librosa.feature.mfcc(y=y, sr=sr))[1:].T\n",
        "  n = 10\n",
        "  result = []\n",
        "  for i in range(n):\n",
        "    sample = pd.DataFrame(mfcc.sample(frac=1/n).mean(axis=0)).T\n",
        "    result.append(logreg.predict(sample))\n",
        "  \n",
        "  result = pd.DataFrame(result).value_counts() / n\n",
        "  result.index = [idx[0] for idx in result.index]\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "logreg_probability(sample_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50F    0.4\n",
              "20M    0.3\n",
              "20F    0.2\n",
              "40F    0.1\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvo1azCjeyJf",
        "outputId": "b0183af2-4826-4a3a-ba17-c64e4d6a5eca"
      },
      "source": [
        "def rand_probability(wav_dir):\n",
        "  \"\"\"Returns the probability that an object belongs to each category using Random Forest\"\"\"\n",
        "  \n",
        "  # # 1. Classify using mean value of whole MFCC vectors of a wav file\n",
        "  # y = remove_silence(wav_dir)\n",
        "  # mfcc = pd.DataFrame(librosa.feature.mfcc(y=y, sr=sr))[1:].T\n",
        "  # result = pd.DataFrame(rand.predict(mfcc)).value_counts()/len(mfcc)  # Result of classification of Random Forest\n",
        "\n",
        "  # # Modify index from ('20F', ) to '20F'\n",
        "  # result.index = [idx[0] for idx in result.index]\n",
        "\n",
        "  \n",
        "  # # 2. Divide a wav file in 'Division' and get probability of each category (prob = counts / Division)\n",
        "  # division = 7\n",
        "  # y = remove_silence(wav_dir)\n",
        "  # result = []\n",
        "  # for i in range(0, len(y), ceil(len(y)/division)):\n",
        "  #   mfcc = pd.DataFrame(pd.DataFrame(librosa.feature.mfcc(y=y[i:i + ceil(len(y)/division)], sr=sr)).mean(axis=1)[1:]).T\n",
        "  #   result.append(rand.predict(mfcc))\n",
        "\n",
        "  # result = pd.DataFrame(result).value_counts() / division\n",
        "  # result.index = [idx[0] for idx in result.index]\n",
        "\n",
        "\n",
        "  # 3. Extract MFCC vectors randomly from wav file at a constant rate\n",
        "  y = remove_silence(wav_dir)\n",
        "  mfcc = pd.DataFrame(librosa.feature.mfcc(y=y, sr=sr))[1:].T\n",
        "  n = 10\n",
        "  result = []\n",
        "  for i in range(n):\n",
        "    sample = pd.DataFrame(mfcc.sample(frac=1/n).mean(axis=0)).T\n",
        "    result.append(rand.predict(sample))\n",
        "  \n",
        "  result = pd.DataFrame(result).value_counts() / n\n",
        "  result.index = [idx[0] for idx in result.index]\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "rand_probability(sample_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20F    0.6\n",
              "50F    0.3\n",
              "40F    0.1\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkue4iJ0e4MO",
        "outputId": "4c33265e-8453-4b73-d08a-ebd2f608eadb"
      },
      "source": [
        "def svm_probability(wav_dir):\n",
        "  \"\"\"Returns the probability that an object belongs to each category using SVM\"\"\"\n",
        "  \n",
        "  # # 1. Classify using mean value of whole MFCC vectors of a wav file\n",
        "  # y = remove_silence(wav_dir)\n",
        "  # mfcc = pd.DataFrame(librosa.feature.mfcc(y=y, sr=sr))[1:].T\n",
        "  # result = pd.DataFrame(svm.predict(mfcc)).value_counts()/len(mfcc)  # Result of classification of SVM\n",
        "\n",
        "  # # Modify index from ('20F', ) to '20F'\n",
        "  # result.index = [idx[0] for idx in result.index]\n",
        "\n",
        "  # # 2. Divide a wav file in 'Division' and get probability of each category (prob = counts / Division)\n",
        "  # division = 7\n",
        "  # y = remove_silence(wav_dir)\n",
        "  # result = []\n",
        "  # for i in range(0, len(y), ceil(len(y)/division)):\n",
        "  #   mfcc = pd.DataFrame(pd.DataFrame(librosa.feature.mfcc(y=y[i:i + ceil(len(y)/division)], sr=sr)).mean(axis=1)[1:]).T\n",
        "  #   result.append(svm.predict(mfcc))\n",
        "\n",
        "  # result = pd.DataFrame(result).value_counts() / division\n",
        "  # result.index = [idx[0] for idx in result.index]\n",
        "\n",
        "\n",
        "  # 3. Extract MFCC vectors randomly from wav file at a constant rate\n",
        "  y = remove_silence(wav_dir)\n",
        "  mfcc = pd.DataFrame(librosa.feature.mfcc(y=y, sr=sr))[1:].T\n",
        "  n = 10\n",
        "  result = []\n",
        "  for i in range(n):\n",
        "    sample = pd.DataFrame(mfcc.sample(frac=1/n).mean(axis=0)).T\n",
        "    result.append(rand.predict(sample))\n",
        "  \n",
        "  result = pd.DataFrame(result).value_counts() / n\n",
        "  result.index = [idx[0] for idx in result.index]\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "svm_probability(sample_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20F    0.4\n",
              "40F    0.3\n",
              "50M    0.1\n",
              "50F    0.1\n",
              "20M    0.1\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcWLDin0hpGu"
      },
      "source": [
        "def table_to_category(df):\n",
        "  \"\"\"Returns the category and probability that the object is most likely to belong to among each category\"\"\"\n",
        "\n",
        "  return [df.idxmax(), df.max()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2lk2PVcrd9H"
      },
      "source": [
        "# Part 3. Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFvmK6m6nAnI"
      },
      "source": [
        "7-1. Classify and Save Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl59V1DoZYEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a5d505-3f25-4b75-c2fc-dfa01786cd70"
      },
      "source": [
        "\"\"\"Predict age and gender of a speech before processing\"\"\"\n",
        "\n",
        "pred_dir = wav_pickle + \"predict_results_20div/\"  # Directory to save prediction results\n",
        "\n",
        "for category in os.listdir(wav_unprocessed):\n",
        "  if category not in categories:\n",
        "    continue\n",
        "\n",
        "  folder_dir = wav_unprocessed + category + \"/\"  # Directory of a parent folder of .wav files\n",
        "\n",
        "  # List to store prediction results(True/False)\n",
        "  stat_list = []  # result by statistical method\n",
        "  LR_list = []\n",
        "  RF_list = []\n",
        "  SVM_list = []\n",
        "  LR_stat_list = []\n",
        "  RF_stat_list = []\n",
        "  SVM_stat_list = []\n",
        "  LR_RF_list = []\n",
        "  LR_SVM_list = []\n",
        "  RF_SVM_list = []\n",
        "  LR_RF_stat_list = []\n",
        "  LR_SVM_stat_list = []\n",
        "  RF_SVM_stat_list = []\n",
        "  LR_RF_SVM_list = []\n",
        "  LR_RF_SVM_stat_list = []\n",
        "  actual_list = []\n",
        "\n",
        "  for folder in os.listdir(folder_dir):\n",
        "    file_dir = folder_dir + folder + \"/\"\n",
        "    print(\"[Now Processing] /\" + category + \"/\" + folder)\n",
        "\n",
        "    for file in os.listdir(file_dir):\n",
        "      if file.endswith(\".wav\"):\n",
        "\n",
        "        # Directory of a .wav file\n",
        "        wav = file_dir + file\n",
        "\n",
        "        try:\n",
        "          mfcc = pd.DataFrame(pd.DataFrame(librosa.feature.mfcc(y=remove_silence(wav), sr=sr)).mean(axis=1)[1:]).T  # [1:]: Remove data on [0] with poor information\n",
        "\n",
        "          # Probability of belonging to each category\n",
        "          stat_prob = statistical_probability(get_features(wav), m_list, s_list)\n",
        "          LR_prob = logreg_probability(wav)\n",
        "          RF_prob = rand_probability(wav)\n",
        "          SVM_prob = svm_probability(wav)\n",
        "\n",
        "          # Save predicted categories in the list\n",
        "          stat_list.append(table_to_category(stat_prob))\n",
        "          LR_list.append(table_to_category(LR_prob))\n",
        "          RF_list.append(table_to_category(RF_prob))\n",
        "          SVM_list.append(table_to_category(SVM_prob))\n",
        "          LR_stat_list.append(table_to_category((LR_prob + stat_prob).fillna(0)/2))\n",
        "          RF_stat_list.append(table_to_category((RF_prob + stat_prob).fillna(0)/2))\n",
        "          SVM_stat_list.append(table_to_category((SVM_prob + stat_prob).fillna(0)/2))\n",
        "          LR_RF_list.append(table_to_category((LR_prob + RF_prob).fillna(0)/2))\n",
        "          LR_SVM_list.append(table_to_category((LR_prob + SVM_prob).fillna(0)/2))\n",
        "          RF_SVM_list.append(table_to_category((RF_prob + SVM_prob).fillna(0)/2))\n",
        "          LR_RF_stat_list.append(table_to_category((LR_prob + RF_prob + stat_prob).fillna(0)/3))\n",
        "          LR_SVM_stat_list.append(table_to_category((LR_prob + SVM_prob + stat_prob).fillna(0)/3))\n",
        "          RF_SVM_stat_list.append(table_to_category((RF_prob + SVM_prob + stat_prob).fillna(0)/3))\n",
        "          LR_RF_SVM_list.append(table_to_category((LR_prob + RF_prob + SVM_prob).fillna(0)/3))\n",
        "          LR_RF_SVM_stat_list.append(table_to_category((LR_prob + RF_prob + SVM_prob + stat_prob).fillna(0)/4))\n",
        "          actual_list.append(category)\n",
        "\n",
        "        except:\n",
        "          print(\"[Error] {}\".format(wav))\n",
        "          continue\n",
        "\n",
        "  pd.DataFrame(stat_list).to_pickle(pred_dir + \"predict_stat_\" + category + \".pkl\")\n",
        "  pd.DataFrame(LR_list).to_pickle(pred_dir + \"predict_LR_\" + category + \".pkl\")\n",
        "  pd.DataFrame(RF_list).to_pickle(pred_dir + \"predict_RF_\" + category + \".pkl\")\n",
        "  pd.DataFrame(SVM_list).to_pickle(pred_dir + \"predict_SVM_\" + category + \".pkl\")\n",
        "  pd.DataFrame(LR_stat_list).to_pickle(pred_dir + \"predict_LR_stat_\" + category + \".pkl\")\n",
        "  pd.DataFrame(RF_stat_list).to_pickle(pred_dir + \"predict_RF_stat_\" + category + \".pkl\")\n",
        "  pd.DataFrame(SVM_stat_list).to_pickle(pred_dir + \"predict_SVM_stat_\" + category + \".pkl\")\n",
        "  pd.DataFrame(LR_RF_list).to_pickle(pred_dir + \"predict_LR_RF_\" + category + \".pkl\")\n",
        "  pd.DataFrame(LR_SVM_list).to_pickle(pred_dir + \"predict_LR_SVM_\" + category + \".pkl\")\n",
        "  pd.DataFrame(RF_SVM_list).to_pickle(pred_dir + \"predict_RF_SVM_\" + category + \".pkl\")\n",
        "  pd.DataFrame(LR_RF_stat_list).to_pickle(pred_dir + \"predict_LR_RF_stat_\" + category + \".pkl\")\n",
        "  pd.DataFrame(LR_SVM_stat_list).to_pickle(pred_dir + \"predict_LR_SVM_stat_\" + category + \".pkl\")\n",
        "  pd.DataFrame(RF_SVM_stat_list).to_pickle(pred_dir + \"predict_RF_SVM_stat_\" + category + \".pkl\")\n",
        "  pd.DataFrame(LR_RF_SVM_list).to_pickle(pred_dir + \"predict_LR_RF_SVM_\" + category + \".pkl\")\n",
        "  pd.DataFrame(LR_RF_SVM_stat_list).to_pickle(pred_dir + \"predict_LR_RF_SVM_stat_\" + category + \".pkl\")\n",
        "  pd.DataFrame(actual_list).to_pickle(pred_dir + \"predict_actual_\" + category + \".pkl\")\n",
        "\n",
        "print(\"[Finished]\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Now Processing] /20F/fv01\n",
            "[Now Processing] /20F/fv02\n",
            "[Now Processing] /20F/fv07\n",
            "[Now Processing] /20F/fv04\n",
            "[Now Processing] /20F/fv03\n",
            "[Now Processing] /20F/fv10\n",
            "[Now Processing] /20F/fv05\n",
            "[Now Processing] /20F/fv08\n",
            "[Now Processing] /20F/fv11\n",
            "[Now Processing] /20F/fv12\n",
            "[Now Processing] /20F/fv06\n",
            "[Now Processing] /20F/fv09\n",
            "[Now Processing] /20F/fv20\n",
            "[Now Processing] /20F/fv15\n",
            "[Now Processing] /20F/fv14\n",
            "[Now Processing] /20F/fv18\n",
            "[Now Processing] /20F/fv17\n",
            "[Now Processing] /20F/fv19\n",
            "[Now Processing] /20F/fv13\n",
            "[Now Processing] /20F/fv16\n",
            "[Now Processing] /20M/mv01\n",
            "[Now Processing] /20M/mv02\n",
            "[Now Processing] /20M/mv07\n",
            "[Now Processing] /20M/mv11\n",
            "[Now Processing] /20M/mv03\n",
            "[Now Processing] /20M/mv08\n",
            "[Now Processing] /20M/mv10\n",
            "[Now Processing] /20M/mv04\n",
            "[Now Processing] /20M/mv12\n",
            "[Now Processing] /20M/mv06\n",
            "[Now Processing] /20M/mv05\n",
            "[Now Processing] /20M/mv09\n",
            "[Now Processing] /20M/mv19\n",
            "[Now Processing] /20M/mv14\n",
            "[Now Processing] /20M/mv15\n",
            "[Now Processing] /20M/mv13\n",
            "[Now Processing] /20M/mv16\n",
            "[Now Processing] /20M/mv20\n",
            "[Now Processing] /20M/mv18\n",
            "[Now Processing] /20M/mv17\n",
            "[Now Processing] /30M/mw03\n",
            "[Now Processing] /30M/mw02\n",
            "[Now Processing] /30M/mw05\n",
            "[Now Processing] /30M/mw08\n",
            "[Now Processing] /30M/mw06\n",
            "[Now Processing] /30M/mw04\n",
            "[Now Processing] /30M/mw10\n",
            "[Now Processing] /30M/mw09\n",
            "[Now Processing] /30M/mw01\n",
            "[Now Processing] /30M/mw07\n",
            "[Now Processing] /30M/mw14\n",
            "[Now Processing] /30M/mw18\n",
            "[Now Processing] /30M/mw17\n",
            "[Now Processing] /30M/mw11\n",
            "[Now Processing] /30M/mw20\n",
            "[Now Processing] /30M/mw19\n",
            "[Now Processing] /30M/mw16\n",
            "[Now Processing] /30M/mw15\n",
            "[Now Processing] /30M/mw13\n",
            "[Now Processing] /50F/fy01\n",
            "[Now Processing] /50F/fy10\n",
            "[Now Processing] /50F/fy08\n",
            "[Now Processing] /50F/fy06\n",
            "[Now Processing] /50F/fy09\n",
            "[Now Processing] /50F/fy02\n",
            "[Now Processing] /50F/fy04\n",
            "[Now Processing] /50F/fy03\n",
            "[Now Processing] /50F/fy07\n",
            "[Now Processing] /50F/fy05\n",
            "[Now Processing] /50F/fy11\n",
            "[Now Processing] /50F/fy13\n",
            "[Now Processing] /50F/fy12\n",
            "[Now Processing] /50F/fz05\n",
            "[Now Processing] /50F/fy18\n",
            "[Now Processing] /50F/fy16\n",
            "[Now Processing] /50F/fy17\n",
            "[Now Processing] /50F/fy14\n",
            "[Now Processing] /50F/fz06\n",
            "[Now Processing] /40F/fx01\n",
            "[Now Processing] /40F/fx08\n",
            "[Now Processing] /40F/fx03\n",
            "[Now Processing] /40F/fx09\n",
            "[Now Processing] /40F/fx02\n",
            "[Now Processing] /40F/fx10\n",
            "[Now Processing] /40F/fx11\n",
            "[Now Processing] /40F/fx04\n",
            "[Now Processing] /40F/fx07\n",
            "[Now Processing] /40F/fx06\n",
            "[Now Processing] /40F/fx05\n",
            "[Now Processing] /40F/fx15\n",
            "[Now Processing] /40F/fx19\n",
            "[Now Processing] /40F/fx17\n",
            "[Now Processing] /40F/fx12\n",
            "[Now Processing] /40F/fx20\n",
            "[Now Processing] /40F/fx18\n",
            "[Now Processing] /40F/fx16\n",
            "[Now Processing] /40F/fx14\n",
            "[Now Processing] /40F/fx13\n",
            "[Now Processing] /50M/my01\n",
            "[Now Processing] /50M/my02\n",
            "[Now Processing] /50M/my06\n",
            "[Now Processing] /50M/my08\n",
            "[Now Processing] /50M/my04\n",
            "[Now Processing] /50M/my10\n",
            "[Now Processing] /50M/my11\n",
            "[Now Processing] /50M/my03\n",
            "[Now Processing] /50M/my09\n",
            "[Now Processing] /50M/my05\n",
            "[Now Processing] /50M/my07\n",
            "[Now Processing] /50M/mz01\n",
            "[Now Processing] /50M/mz09\n",
            "[Now Processing] /50M/mz03\n",
            "[Now Processing] /50M/mz08\n",
            "[Now Processing] /50M/mz04\n",
            "[Now Processing] /50M/mz07\n",
            "[Now Processing] /50M/mz05\n",
            "[Now Processing] /50M/mz06\n",
            "[Now Processing] /50M/mz02\n",
            "[Finished]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfMpRfxcVgs4"
      },
      "source": [
        "Load prediction data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICvisO71UiWu"
      },
      "source": [
        "pred_dir = wav_pickle + \"predict_results_20div/\"\n",
        "\n",
        "stat_predict = pd.DataFrame([])\n",
        "lr_predict = pd.DataFrame([])\n",
        "rf_predict = pd.DataFrame([])\n",
        "svm_predict = pd.DataFrame([])\n",
        "lr_stat_predict = pd.DataFrame([])\n",
        "rf_stat_predict = pd.DataFrame([])\n",
        "svm_stat_predict = pd.DataFrame([])\n",
        "lr_rf_predict = pd.DataFrame([])\n",
        "lr_svm_predict = pd.DataFrame([])\n",
        "rf_svm_predict = pd.DataFrame([])\n",
        "lr_rf_stat_predict = pd.DataFrame([])\n",
        "lr_svm_stat_predict = pd.DataFrame([])\n",
        "rf_svm_stat_predict = pd.DataFrame([])\n",
        "lr_rf_svm_predict = pd.DataFrame([])\n",
        "lr_rf_svm_stat_predict = pd.DataFrame([])\n",
        "actual_predict = pd.DataFrame([])\n",
        "\n",
        "for file in os.listdir(pred_dir):\n",
        "  for category in categories:\n",
        "    if file[-7:-4] == category:\n",
        "      if file[8:-8] == \"LR_RF_SVM_stat\":\n",
        "        lr_rf_svm_stat_predict = pd.concat([lr_rf_svm_stat_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"LR_RF_SVM\":\n",
        "        lr_rf_svm_predict = pd.concat([lr_rf_svm_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"LR_RF_stat\":\n",
        "        lr_rf_stat_predict = pd.concat([lr_rf_stat_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"LR_SVM_stat\":\n",
        "        lr_svm_stat_predict = pd.concat([lr_svm_stat_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"RF_SVM_stat\":\n",
        "        rf_svm_stat_predict = pd.concat([rf_svm_stat_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"LR_RF\":\n",
        "        lr_rf_predict = pd.concat([lr_rf_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"LR_SVM\":\n",
        "        lr_svm_predict = pd.concat([lr_svm_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"RF_SVM\":\n",
        "        rf_svm_predict = pd.concat([rf_svm_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"LR_stat\":\n",
        "        lr_stat_predict = pd.concat([lr_stat_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"RF_stat\":\n",
        "        rf_stat_predict = pd.concat([rf_stat_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"SVM_stat\":\n",
        "        svm_stat_predict = pd.concat([svm_stat_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"stat\":\n",
        "        stat_predict = pd.concat([stat_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"LR\":\n",
        "        lr_predict = pd.concat([lr_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"RF\":\n",
        "        rf_predict = pd.concat([rf_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      elif file[8:-8] == \"SVM\":\n",
        "        svm_predict = pd.concat([svm_predict, pd.read_pickle(pred_dir + file)['0']])\n",
        "      else:\n",
        "        actual_predict = pd.concat([actual_predict, pd.read_pickle(pred_dir + file)['0']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7dUCgahag6G"
      },
      "source": [
        "Classification Performance of Statistical Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BFPE8NUauws",
        "outputId": "962d7749-f0ff-4039-ad83-42bf26cd2efc"
      },
      "source": [
        "print(confusion_matrix(actual_predict, stat_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, stat_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[82668     0    18 14988 12894   972]\n",
            " [   42 42636 26022  2418   348 27132]\n",
            " [    6 44454 23490  1596   228 36168]\n",
            " [79812     0     0 15792 15360   570]\n",
            " [28860     6   270 12270  3096  1686]\n",
            " [  180 19254  8340  6564   870 13254]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.4315    0.7412    0.5455    111540\n",
            "         20M     0.4009    0.4324    0.4161     98598\n",
            "         30M     0.4040    0.2217    0.2863    105942\n",
            "         40F     0.2945    0.1416    0.1912    111534\n",
            "         50F     0.0944    0.0670    0.0784     46188\n",
            "         50M     0.1661    0.2735    0.2067     48462\n",
            "\n",
            "    accuracy                         0.3464    522264\n",
            "   macro avg     0.2986    0.3129    0.2874    522264\n",
            "weighted avg     0.3365    0.3464    0.3201    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lT6FH4kZXRM"
      },
      "source": [
        "Comparison of performance before and after combining statistical method on each model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHhJJdHZdzr0"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzf65EaibwdU",
        "outputId": "c67b3aeb-7c48-4f75-f686-a9d2086f7c8e"
      },
      "source": [
        "print(confusion_matrix(actual_predict, lr_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, lr_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[99150  1434   666  7284  2250   756]\n",
            " [ 1902 75240 14688   600   264  5904]\n",
            " [  270 11256 84948   108   324  9036]\n",
            " [11958  1842   936 85770  9234  1794]\n",
            " [ 7230   624  1596 20514 14604  1620]\n",
            " [ 1284  8190  9300  1896   798 26994]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.8141    0.8889    0.8499    111540\n",
            "         20M     0.7632    0.7631    0.7631     98598\n",
            "         30M     0.7576    0.8018    0.7791    105942\n",
            "         40F     0.7383    0.7690    0.7533    111534\n",
            "         50F     0.5316    0.3162    0.3965     46188\n",
            "         50M     0.5855    0.5570    0.5709     48462\n",
            "\n",
            "    accuracy                         0.7404    522264\n",
            "   macro avg     0.6984    0.6827    0.6855    522264\n",
            "weighted avg     0.7306    0.7404    0.7325    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0paNmXScBB7",
        "outputId": "2034722c-bcd7-4b28-cab8-9b87bdbf71cc"
      },
      "source": [
        "print(confusion_matrix(actual_predict, lr_stat_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, lr_stat_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[101622    786    282   6660   1872    318]\n",
            " [  1782  76476  13782    558    240   5760]\n",
            " [   252  12174  84450     96    252   8718]\n",
            " [ 14310   1302    558  86082   8364    918]\n",
            " [  8502    456   1296  21114  13950    870]\n",
            " [  1368   8652   9384   2070    870  26118]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.7949    0.9111    0.8491    111540\n",
            "         20M     0.7659    0.7756    0.7708     98598\n",
            "         30M     0.7695    0.7971    0.7831    105942\n",
            "         40F     0.7384    0.7718    0.7547    111534\n",
            "         50F     0.5460    0.3020    0.3889     46188\n",
            "         50M     0.6116    0.5389    0.5730     48462\n",
            "\n",
            "    accuracy                         0.7443    522264\n",
            "   macro avg     0.7044    0.6828    0.6866    522264\n",
            "weighted avg     0.7332    0.7443    0.7344    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZwsq0rad2Yy"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlYnrYn3bwp0",
        "outputId": "e87bb53c-d790-42c3-a8d9-38fd729f70d6"
      },
      "source": [
        "print(confusion_matrix(actual_predict, rf_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, rf_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[104778    978    654   4518    438    174]\n",
            " [   342  92388   3786    186     42   1854]\n",
            " [    60   1206 102252    120     24   2280]\n",
            " [  3432    606    882 105756    552    306]\n",
            " [  3642    354    342  11208  30246    396]\n",
            " [   498    810   2124    480    210  44340]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.9293    0.9394    0.9343    111540\n",
            "         20M     0.9590    0.9370    0.9479     98598\n",
            "         30M     0.9292    0.9652    0.9469    105942\n",
            "         40F     0.8650    0.9482    0.9047    111534\n",
            "         50F     0.9598    0.6548    0.7785     46188\n",
            "         50M     0.8985    0.9149    0.9066     48462\n",
            "\n",
            "    accuracy                         0.9186    522264\n",
            "   macro avg     0.9235    0.8933    0.9031    522264\n",
            "weighted avg     0.9210    0.9186    0.9167    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WnAeHRecD_o",
        "outputId": "5571e825-5514-49c5-dade-f4bf4fa4533e"
      },
      "source": [
        "print(confusion_matrix(actual_predict, rf_stat_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, rf_stat_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[106386    432    282   4068    306     66]\n",
            " [   318  92886   3384    150     54   1806]\n",
            " [    54   1428 102204    126     12   2118]\n",
            " [  4296    360    540 105804    432    102]\n",
            " [  4680    180    228  11766  29100    234]\n",
            " [   558    798   1980    660    294  44172]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.9148    0.9538    0.9339    111540\n",
            "         20M     0.9667    0.9421    0.9542     98598\n",
            "         30M     0.9409    0.9647    0.9527    105942\n",
            "         40F     0.8632    0.9486    0.9039    111534\n",
            "         50F     0.9636    0.6300    0.7619     46188\n",
            "         50M     0.9108    0.9115    0.9111     48462\n",
            "\n",
            "    accuracy                         0.9201    522264\n",
            "   macro avg     0.9267    0.8918    0.9030    522264\n",
            "weighted avg     0.9228    0.9201    0.9178    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1ouI1Gpd3pR"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFIVXYWhbw37",
        "outputId": "b0d69d7d-a675-4a79-9757-aac8db8429d1"
      },
      "source": [
        "print(confusion_matrix(actual_predict, svm_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, svm_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[104736    942    564   4716    390    192]\n",
            " [   366  92526   3612    204     60   1830]\n",
            " [    90   1248 102096     90     60   2358]\n",
            " [  3450    582    918 105606    654    324]\n",
            " [  3726    336    300  11076  30276    474]\n",
            " [   528    666   2070    468    168  44562]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.9277    0.9390    0.9333    111540\n",
            "         20M     0.9608    0.9384    0.9495     98598\n",
            "         30M     0.9319    0.9637    0.9475    105942\n",
            "         40F     0.8645    0.9469    0.9038    111534\n",
            "         50F     0.9579    0.6555    0.7783     46188\n",
            "         50M     0.8959    0.9195    0.9076     48462\n",
            "\n",
            "    accuracy                         0.9187    522264\n",
            "   macro avg     0.9231    0.8938    0.9033    522264\n",
            "weighted avg     0.9210    0.9187    0.9169    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N82AxqGcHmS",
        "outputId": "9e261fe9-31a0-4d2f-a692-e4cdd36a4e39"
      },
      "source": [
        "print(confusion_matrix(actual_predict, svm_stat_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, svm_stat_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[60599  1127  2121  3105   410 44178]\n",
            " [46414 47524  1779  1797   148   936]\n",
            " [  224 46420 57069   123    51  2055]\n",
            " [ 2791   826 47059 59479   302  1077]\n",
            " [ 1716   109   152 43952   201    58]\n",
            " [ 4602   210   174 14028 29242   206]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.5209    0.5433    0.5318    111540\n",
            "         20M     0.4939    0.4820    0.4879     98598\n",
            "         30M     0.5267    0.5387    0.5326    105942\n",
            "         40F     0.4856    0.5333    0.5083    111534\n",
            "         50F     0.0066    0.0044    0.0053     46188\n",
            "         50M     0.0042    0.0043    0.0042     48462\n",
            "\n",
            "    accuracy                         0.4310    522264\n",
            "   macro avg     0.3397    0.3510    0.3450    522264\n",
            "weighted avg     0.4160    0.4310    0.4232    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2CAfRcjZlgf"
      },
      "source": [
        "Logistic Regression + Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgnd6kgCbxFW",
        "outputId": "1eb59c85-4f1c-4678-ded9-4ca12d2cdd1a"
      },
      "source": [
        "print(confusion_matrix(actual_predict, lr_rf_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, lr_rf_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[106182    870    420   3462    378    228]\n",
            " [   990  90828   4518    312    126   1824]\n",
            " [   180   4188  98742     48     48   2736]\n",
            " [  7212   1194    960 100002   1614    552]\n",
            " [  5928    420    762  15834  22710    534]\n",
            " [   918   3252   5298    948    252  37794]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.8746    0.9520    0.9116    111540\n",
            "         20M     0.9015    0.9212    0.9112     98598\n",
            "         30M     0.8920    0.9320    0.9116    105942\n",
            "         40F     0.8292    0.8966    0.8616    111534\n",
            "         50F     0.9038    0.4917    0.6369     46188\n",
            "         50M     0.8655    0.7799    0.8204     48462\n",
            "\n",
            "    accuracy                         0.8736    522264\n",
            "   macro avg     0.8777    0.8289    0.8422    522264\n",
            "weighted avg     0.8752    0.8736    0.8681    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLnmuklMbxU2",
        "outputId": "aa675524-7c66-4eba-ed11-d3c4f1a89089"
      },
      "source": [
        "print(confusion_matrix(actual_predict, lr_rf_stat_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, lr_rf_stat_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[106494    666    300   3546    402    132]\n",
            " [  1110  90168   4836    306    144   2034]\n",
            " [   144   3990  98688     54     48   3018]\n",
            " [  7284    948    732 100416   1758    396]\n",
            " [  6288    276    528  15870  22812    414]\n",
            " [   948   3012   4950   1074    258  38220]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.8710    0.9548    0.9110    111540\n",
            "         20M     0.9102    0.9145    0.9124     98598\n",
            "         30M     0.8969    0.9315    0.9139    105942\n",
            "         40F     0.8281    0.9003    0.8627    111534\n",
            "         50F     0.8973    0.4939    0.6371     46188\n",
            "         50M     0.8644    0.7887    0.8248     48462\n",
            "\n",
            "    accuracy                         0.8746    522264\n",
            "   macro avg     0.8780    0.8306    0.8436    522264\n",
            "weighted avg     0.8762    0.8746    0.8693    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJlPxwmyZr_O"
      },
      "source": [
        "Logistic Regression + SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXQhoON6cWOs",
        "outputId": "c61084b6-99ef-4777-b6f0-74945759697b"
      },
      "source": [
        "print(confusion_matrix(actual_predict, lr_svm_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, lr_svm_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[106212    894    390   3450    414    180]\n",
            " [   924  91164   4296    360    102   1752]\n",
            " [   114   4146  98880     72     72   2658]\n",
            " [  7296   1236    966  99972   1578    486]\n",
            " [  5934    384    714  16128  22518    510]\n",
            " [   954   3150   5214    942    270  37932]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.8746    0.9522    0.9118    111540\n",
            "         20M     0.9028    0.9246    0.9136     98598\n",
            "         30M     0.8952    0.9333    0.9139    105942\n",
            "         40F     0.8267    0.8963    0.8601    111534\n",
            "         50F     0.9024    0.4875    0.6330     46188\n",
            "         50M     0.8716    0.7827    0.8248     48462\n",
            "\n",
            "    accuracy                         0.8744    522264\n",
            "   macro avg     0.8789    0.8295    0.8429    522264\n",
            "weighted avg     0.8761    0.8744    0.8688    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea2FqsRZb9mE",
        "outputId": "dcb9413c-11a8-45cf-b96d-d034f51edb1a"
      },
      "source": [
        "print(confusion_matrix(actual_predict, lr_svm_stat_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, lr_svm_stat_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[106512    666    258   3588    402    114]\n",
            " [   996  90570   4524    384    108   2016]\n",
            " [   102   4014  98796     66     72   2892]\n",
            " [  7500    942    630 100392   1656    414]\n",
            " [  6324    276    522  16182  22470    414]\n",
            " [  1014   3012   4938   1008    294  38196]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.8699    0.9549    0.9104    111540\n",
            "         20M     0.9104    0.9186    0.9145     98598\n",
            "         30M     0.9009    0.9325    0.9164    105942\n",
            "         40F     0.8255    0.9001    0.8612    111534\n",
            "         50F     0.8987    0.4865    0.6313     46188\n",
            "         50M     0.8672    0.7882    0.8258     48462\n",
            "\n",
            "    accuracy                         0.8749    522264\n",
            "   macro avg     0.8788    0.8301    0.8433    522264\n",
            "weighted avg     0.8766    0.8749    0.8693    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NROug2u_ZwKj"
      },
      "source": [
        "Random Forest + SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWOxefG-cZ0q",
        "outputId": "21cc7530-77fa-458d-ca72-2e1303a9e24a"
      },
      "source": [
        "print(confusion_matrix(actual_predict, rf_svm_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, rf_svm_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[106482    714    414   3636    210     84]\n",
            " [   390  93924   2748    114     36   1386]\n",
            " [    54   1140 102960     78     18   1692]\n",
            " [  3726    612    834 105912    252    198]\n",
            " [  4002    330    318  11532  29730    276]\n",
            " [   552    684   2112    504    150  44460]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.9243    0.9547    0.9392    111540\n",
            "         20M     0.9643    0.9526    0.9584     98598\n",
            "         30M     0.9413    0.9719    0.9563    105942\n",
            "         40F     0.8697    0.9496    0.9079    111534\n",
            "         50F     0.9781    0.6437    0.7764     46188\n",
            "         50M     0.9244    0.9174    0.9209     48462\n",
            "\n",
            "    accuracy                         0.9257    522264\n",
            "   macro avg     0.9337    0.8983    0.9099    522264\n",
            "weighted avg     0.9284    0.9257    0.9235    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ3cyfkRb9ju",
        "outputId": "b8e0e35b-6817-41e7-ba2a-238a272b369a"
      },
      "source": [
        "print(confusion_matrix(actual_predict, rf_svm_stat_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, rf_svm_stat_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[106758    504    294   3726    216     42]\n",
            " [   270  93738   2880    126     42   1542]\n",
            " [    36   1068 102972     72     18   1776]\n",
            " [  3756    438    606 106320    270    144]\n",
            " [  4206    216    234  11586  29730    216]\n",
            " [   558    570   1926    522    180  44706]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.9236    0.9571    0.9401    111540\n",
            "         20M     0.9710    0.9507    0.9608     98598\n",
            "         30M     0.9455    0.9720    0.9585    105942\n",
            "         40F     0.8690    0.9533    0.9092    111534\n",
            "         50F     0.9762    0.6437    0.7758     46188\n",
            "         50M     0.9232    0.9225    0.9228     48462\n",
            "\n",
            "    accuracy                         0.9272    522264\n",
            "   macro avg     0.9347    0.8999    0.9112    522264\n",
            "weighted avg     0.9299    0.9272    0.9250    522264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sePcOyt3aMIj"
      },
      "source": [
        "Logistic Regression + Random Forest + SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_uMngWMb9hm",
        "outputId": "6e3547a2-6693-44a7-c7d9-eaa1828c25ca"
      },
      "source": [
        "print(confusion_matrix(actual_predict, lr_rf_svm_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, lr_rf_svm_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[17832   111    49   542    39    17]\n",
            " [  167 15398   554    40    17   257]\n",
            " [   17   321 16956    10     6   347]\n",
            " [  942   145   129 17175   140    58]\n",
            " [  931    43    67  2390  4212    55]\n",
            " [  148   289   601   144    34  6861]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.8900    0.9592    0.9233     18590\n",
            "         20M     0.9443    0.9370    0.9406     16433\n",
            "         30M     0.9237    0.9603    0.9417     17657\n",
            "         40F     0.8460    0.9239    0.8833     18589\n",
            "         50F     0.9469    0.5472    0.6936      7698\n",
            "         50M     0.9034    0.8494    0.8756      8077\n",
            "\n",
            "    accuracy                         0.9011     87044\n",
            "   macro avg     0.9090    0.8628    0.8763     87044\n",
            "weighted avg     0.9040    0.9011    0.8970     87044\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9DA5Jb2b9cW",
        "outputId": "2c0a52a7-4f37-4ee7-b2e6-61791190179a"
      },
      "source": [
        "print(confusion_matrix(actual_predict, lr_rf_svm_stat_predict), \"\\n\")\n",
        "print(classification_report(actual_predict, lr_rf_svm_stat_predict, target_names = categories, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[17832   111    49   542    39    17]\n",
            " [  167 15398   554    40    17   257]\n",
            " [   17   321 16956    10     6   347]\n",
            " [  942   145   129 17175   140    58]\n",
            " [  931    43    67  2390  4212    55]\n",
            " [  148   289   601   144    34  6861]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         20F     0.8900    0.9592    0.9233     18590\n",
            "         20M     0.9443    0.9370    0.9406     16433\n",
            "         30M     0.9237    0.9603    0.9417     17657\n",
            "         40F     0.8460    0.9239    0.8833     18589\n",
            "         50F     0.9469    0.5472    0.6936      7698\n",
            "         50M     0.9034    0.8494    0.8756      8077\n",
            "\n",
            "    accuracy                         0.9011     87044\n",
            "   macro avg     0.9090    0.8628    0.8763     87044\n",
            "weighted avg     0.9040    0.9011    0.8970     87044\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sstzdoYNctt"
      },
      "source": [
        "Classification Performance Comparison(For Accuracy)  \n",
        "*   Stat(0.3464)  \n",
        "*   LR(0.7404) < LR+Stat(0.7443) (+0.0039)  \n",
        "*   RF(0.9186) < RF+Stat(0.9201) (+0.0015)  \n",
        "*   SVM(0.9187) > SVM+Stat(0.4310) (-0.4877)  \n",
        "*   LR+RF(0.8736) < LR+RF+Stat(0.8746) (+0.0010)  \n",
        "*   LR+SVM(0.8744) < LR+SVM+Stat(0.8749) (+0.0005)  \n",
        "*   RF+SVM(0.9257) < RF+SVM+Stat(0.9272) (+0.0015)  \n",
        "*   LR+RF+SVM(0.9011) = LR+RF+SVM+Stat(0.9011) (+-0.0000)  \n",
        "\n",
        "SVM+Stat : 0.9187 -> 0.4310 (-0.4877)  \n",
        "LR+RF+SVM+Stat : 0.9011 -> 0.9011 (+-0.0000)  \n",
        "Performance of all other models improved after combining statistical method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aqpYJ0TMOph"
      },
      "source": [
        "# Hypothesis Test\n",
        "\n",
        "H0: mu_bef >= mu_aft  \n",
        "HA: mu_bef < mu_aft  \n",
        "a = 0.05  \n",
        "\n",
        "i) Paired t-test for all models  \n",
        "*   n = 7\n",
        "*   m1 = 0.8789, m2 = 0.8105\n",
        "*   Var1 = 0.004179, Var2 = 0.03175\n",
        "*   P(T<=t) = 0.1825 > a  \n",
        "Combining statistical methods does not result in improved classification performance\n",
        "\n",
        "ii) Paired t-test for all models except outliers(SVM, SVM+Stat)\n",
        "*   n = 6\n",
        "*   m1 = 0.8723, m2 = 8737\n",
        "*   Var1 = 0.004646, Var2 = 0.004503\n",
        "*   P(T<=t) = 0.02633 < a  \n",
        "Combining statistical methods results in improved classification performance  "
      ]
    }
  ]
}